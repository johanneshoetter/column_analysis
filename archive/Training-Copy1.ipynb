{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pytorch implementation of Pointer Network.\n",
    "http://arxiv.org/pdf/1506.03134v1.pdf.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PointerNet import PointerNet\n",
    "from Data_Generator import TSPDataset\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Pytorch implementation of Pointer-Net\")\n",
    "\n",
    "# Data\n",
    "parser.add_argument('--train_size', default=1000000, type=int, help='Training data size')\n",
    "parser.add_argument('--val_size', default=10000, type=int, help='Validation data size')\n",
    "parser.add_argument('--test_size', default=10000, type=int, help='Test data size')\n",
    "parser.add_argument('--batch_size', default=256, type=int, help='Batch size')\n",
    "# Train\n",
    "parser.add_argument('--nof_epoch', default=50000, type=int, help='Number of epochs')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, help='Learning rate')\n",
    "# GPU\n",
    "parser.add_argument('--gpu', default=True, action='store_true', help='Enable gpu')\n",
    "# TSP\n",
    "parser.add_argument('--nof_points', type=int, default=5, help='Number of points in TSP')\n",
    "# Network\n",
    "parser.add_argument('--embedding_size', type=int, default=128, help='Embedding size')\n",
    "parser.add_argument('--hiddens', type=int, default=512, help='Number of hidden units')\n",
    "parser.add_argument('--nof_lstms', type=int, default=2, help='Number of LSTM layers')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout value')\n",
    "parser.add_argument('--bidir', default=True, action='store_true', help='Bidirectional')\n",
    "\n",
    "params = parser.parse_args()\n",
    "\n",
    "if params.gpu and torch.cuda.is_available():\n",
    "    USE_CUDA = True\n",
    "    print('Using GPU, %i devices.' % torch.cuda.device_count())\n",
    "else:\n",
    "    USE_CUDA = False\n",
    "\n",
    "model = PointerNet(params.embedding_size,\n",
    "                   params.hiddens,\n",
    "                   params.nof_lstms,\n",
    "                   params.dropout,\n",
    "                   params.bidir)\n",
    "\n",
    "dataset = TSPDataset(params.train_size,\n",
    "                     params.nof_points)\n",
    "\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=params.batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    net = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "CCE = torch.nn.CrossEntropyLoss()\n",
    "model_optim = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                model.parameters()),\n",
    "                         lr=params.lr)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(params.nof_epoch):\n",
    "    batch_loss = []\n",
    "    iterator = tqdm(dataloader, unit='Batch')\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(iterator):\n",
    "        iterator.set_description('Batch %i/%i' % (epoch+1, params.nof_epoch))\n",
    "\n",
    "        train_batch = Variable(sample_batched['Points'])\n",
    "        target_batch = Variable(sample_batched['Solution'])\n",
    "\n",
    "        if USE_CUDA:\n",
    "            train_batch = train_batch.cuda()\n",
    "            target_batch = target_batch.cuda()\n",
    "\n",
    "        o, p = model(train_batch)\n",
    "        o = o.contiguous().view(-1, o.size()[-1])\n",
    "\n",
    "        target_batch = target_batch.view(-1)\n",
    "\n",
    "        loss = CCE(o, target_batch)\n",
    "\n",
    "        losses.append(loss.data[0])\n",
    "        batch_loss.append(loss.data[0])\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        iterator.set_postfix(loss='{}'.format(loss.data[0]))\n",
    "\n",
    "    iterator.set_postfix(loss=np.average(batch_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
